{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12cc5e08",
   "metadata": {},
   "source": [
    "# Movie recommendation system\n",
    "Explore different models for semantic text matching.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62a0a1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060ccc88",
   "metadata": {},
   "source": [
    "# Load dataset\n",
    "Data is already prepared in folder ``data`` of this repository. Source: https://www.kaggle.com/rounakbanik/the-movies-dataset/movies_metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7f40f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tahera/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>sentence</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 119050, 'name': 'Grumpy Old Men Collect...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15602</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>en</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>False</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16000000</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31357</td>\n",
       "      <td>tt0114885</td>\n",
       "      <td>en</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>81452156.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Friends are the people who let you be yourself...</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>False</td>\n",
       "      <td>6.1</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 96871, 'name': 'Father of the Bride Col...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11862</td>\n",
       "      <td>tt0113041</td>\n",
       "      <td>en</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-02-10</td>\n",
       "      <td>76578911.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Just When His World Is Back To Normal... He's ...</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>False</td>\n",
       "      <td>5.7</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                              belongs_to_collection    budget  \\\n",
       "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "1  False                                                NaN  65000000   \n",
       "2  False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n",
       "3  False                                                NaN  16000000   \n",
       "4  False  {'id': 96871, 'name': 'Father of the Bride Col...         0   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
       "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
       "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n",
       "3  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
       "4                     [{'id': 35, 'name': 'Comedy'}]   \n",
       "\n",
       "                               homepage     id    imdb_id original_language  \\\n",
       "0  http://toystory.disney.com/toy-story    862  tt0114709                en   \n",
       "1                                   NaN   8844  tt0113497                en   \n",
       "2                                   NaN  15602  tt0113228                en   \n",
       "3                                   NaN  31357  tt0114885                en   \n",
       "4                                   NaN  11862  tt0113041                en   \n",
       "\n",
       "                original_title  \\\n",
       "0                    Toy Story   \n",
       "1                      Jumanji   \n",
       "2             Grumpier Old Men   \n",
       "3            Waiting to Exhale   \n",
       "4  Father of the Bride Part II   \n",
       "\n",
       "                                            sentence  ... release_date  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...  ...   1995-10-30   \n",
       "1  When siblings Judy and Peter discover an encha...  ...   1995-12-15   \n",
       "2  A family wedding reignites the ancient feud be...  ...   1995-12-22   \n",
       "3  Cheated on, mistreated and stepped on, the wom...  ...   1995-12-22   \n",
       "4  Just when George Banks has recovered from his ...  ...   1995-02-10   \n",
       "\n",
       "       revenue runtime                                   spoken_languages  \\\n",
       "0  373554033.0    81.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "1  262797249.0   104.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...   \n",
       "2          0.0   101.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "3   81452156.0   127.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "4   76578911.0   106.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "\n",
       "     status                                            tagline  \\\n",
       "0  Released                                                NaN   \n",
       "1  Released          Roll the dice and unleash the excitement!   \n",
       "2  Released  Still Yelling. Still Fighting. Still Ready for...   \n",
       "3  Released  Friends are the people who let you be yourself...   \n",
       "4  Released  Just When His World Is Back To Normal... He's ...   \n",
       "\n",
       "                         title  video vote_average vote_count  \n",
       "0                    Toy Story  False          7.7     5415.0  \n",
       "1                      Jumanji  False          6.9     2413.0  \n",
       "2             Grumpier Old Men  False          6.5       92.0  \n",
       "3            Waiting to Exhale  False          6.1       34.0  \n",
       "4  Father of the Bride Part II  False          5.7      173.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATAPATH = '../data/movies_metadata.csv' \n",
    "\n",
    "df = pd.read_csv(DATAPATH)\n",
    "df = df[~df.overview.isna()]\n",
    "df.rename(columns={'overview':'sentence'}, inplace=True)\n",
    "print(len(df))\n",
    "df = df.iloc[:20000]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffe41ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning sentences...\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "MIN_WORDS = 4\n",
    "MAX_WORDS = 200\n",
    "\n",
    "PATTERN_S = re.compile(\"\\'s\")  # matches `'s` from text  \n",
    "PATTERN_RN = re.compile(\"\\\\r\\\\n\") #matches `\\r` and `\\n`\n",
    "PATTERN_PUNC = re.compile(r\"[^\\w\\s]\") # matches all non 0-9 A-z whitespace \n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Series of cleaning. String to lower case, remove non words characters and numbers.\n",
    "        text (str): input text\n",
    "    return (str): modified initial text\n",
    "    \"\"\"\n",
    "    text = text.lower()  # lowercase text\n",
    "    text = re.sub(PATTERN_S, ' ', text)\n",
    "    text = re.sub(PATTERN_RN, ' ', text)\n",
    "    text = re.sub(PATTERN_PUNC, ' ', text)\n",
    "    return text\n",
    "\n",
    "def tokenizer(sentence, min_words=MIN_WORDS, max_words=MAX_WORDS, stopwords=STOPWORDS, lemmatize=True):\n",
    "    \"\"\"\n",
    "    Lemmatize, tokenize, crop and remove stop words.\n",
    "    \"\"\"\n",
    "    if lemmatize:\n",
    "        stemmer = WordNetLemmatizer()\n",
    "        tokens = [stemmer.lemmatize(w) for w in word_tokenize(sentence)]\n",
    "    else:\n",
    "        tokens = [w for w in word_tokenize(sentence)]\n",
    "    token = [w for w in tokens if (len(w) > min_words and len(w) < max_words\n",
    "                                                        and w not in stopwords)]\n",
    "    return tokens    \n",
    "\n",
    "\n",
    "def clean_sentences(df):\n",
    "    \"\"\"\n",
    "    Remove irrelavant characters (in new column clean_sentence).\n",
    "    Lemmatize, tokenize words into list of words (in new column tok_lem_sentence).\n",
    "    \"\"\"\n",
    "    print('Cleaning sentences...')\n",
    "    df['clean_sentence'] = df['sentence'].apply(clean_text)\n",
    "    df['tok_lem_sentence'] = df['clean_sentence'].apply(\n",
    "        lambda x: tokenizer(x, min_words=MIN_WORDS, max_words=MAX_WORDS, stopwords=STOPWORDS, lemmatize=True))\n",
    "    return df\n",
    "    \n",
    "df = clean_sentences(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ed392d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>clean_sentence</th>\n",
       "      <th>tok_lem_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>led by woody  andy  toys live happily in his r...</td>\n",
       "      <td>[led, by, woody, andy, toy, live, happily, in,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>when siblings judy and peter discover an encha...</td>\n",
       "      <td>[when, sibling, judy, and, peter, discover, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>a family wedding reignites the ancient feud be...</td>\n",
       "      <td>[a, family, wedding, reignites, the, ancient, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>cheated on  mistreated and stepped on  the wom...</td>\n",
       "      <td>[cheated, on, mistreated, and, stepped, on, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>just when george banks has recovered from his ...</td>\n",
       "      <td>[just, when, george, bank, ha, recovered, from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20131</th>\n",
       "      <td>After a lifetime of hiding, Chely Wright becom...</td>\n",
       "      <td>after a lifetime of hiding  chely wright becom...</td>\n",
       "      <td>[after, a, lifetime, of, hiding, chely, wright...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20132</th>\n",
       "      <td>In 1989, five black and Latino teenagers from ...</td>\n",
       "      <td>in 1989  five black and latino teenagers from ...</td>\n",
       "      <td>[in, 1989, five, black, and, latino, teenager,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20133</th>\n",
       "      <td>Arkin escapes with his life from the vicious g...</td>\n",
       "      <td>arkin escapes with his life from the vicious g...</td>\n",
       "      <td>[arkin, escape, with, his, life, from, the, vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20134</th>\n",
       "      <td>Remake of a hit film from 1990, \"The Cherry Or...</td>\n",
       "      <td>remake of a hit film from 1990   the cherry or...</td>\n",
       "      <td>[remake, of, a, hit, film, from, 1990, the, ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20135</th>\n",
       "      <td>Chronicles the adventures of Franklin Delano R...</td>\n",
       "      <td>chronicles the adventures of franklin delano r...</td>\n",
       "      <td>[chronicle, the, adventure, of, franklin, dela...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  \\\n",
       "0      Led by Woody, Andy's toys live happily in his ...   \n",
       "1      When siblings Judy and Peter discover an encha...   \n",
       "2      A family wedding reignites the ancient feud be...   \n",
       "3      Cheated on, mistreated and stepped on, the wom...   \n",
       "4      Just when George Banks has recovered from his ...   \n",
       "...                                                  ...   \n",
       "20131  After a lifetime of hiding, Chely Wright becom...   \n",
       "20132  In 1989, five black and Latino teenagers from ...   \n",
       "20133  Arkin escapes with his life from the vicious g...   \n",
       "20134  Remake of a hit film from 1990, \"The Cherry Or...   \n",
       "20135  Chronicles the adventures of Franklin Delano R...   \n",
       "\n",
       "                                          clean_sentence  \\\n",
       "0      led by woody  andy  toys live happily in his r...   \n",
       "1      when siblings judy and peter discover an encha...   \n",
       "2      a family wedding reignites the ancient feud be...   \n",
       "3      cheated on  mistreated and stepped on  the wom...   \n",
       "4      just when george banks has recovered from his ...   \n",
       "...                                                  ...   \n",
       "20131  after a lifetime of hiding  chely wright becom...   \n",
       "20132  in 1989  five black and latino teenagers from ...   \n",
       "20133  arkin escapes with his life from the vicious g...   \n",
       "20134  remake of a hit film from 1990   the cherry or...   \n",
       "20135  chronicles the adventures of franklin delano r...   \n",
       "\n",
       "                                        tok_lem_sentence  \n",
       "0      [led, by, woody, andy, toy, live, happily, in,...  \n",
       "1      [when, sibling, judy, and, peter, discover, an...  \n",
       "2      [a, family, wedding, reignites, the, ancient, ...  \n",
       "3      [cheated, on, mistreated, and, stepped, on, th...  \n",
       "4      [just, when, george, bank, ha, recovered, from...  \n",
       "...                                                  ...  \n",
       "20131  [after, a, lifetime, of, hiding, chely, wright...  \n",
       "20132  [in, 1989, five, black, and, latino, teenager,...  \n",
       "20133  [arkin, escape, with, his, life, from, the, vi...  \n",
       "20134  [remake, of, a, hit, film, from, 1990, the, ch...  \n",
       "20135  [chronicle, the, adventure, of, franklin, dela...  \n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "df[['sentence', 'clean_sentence', 'tok_lem_sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd8b77e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[['clean_sentence']].to_csv('clean_movies.txt', index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a87bbf",
   "metadata": {},
   "source": [
    "## Query sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd7f75fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_sentence = 'a crime story with a beautiful woman' \n",
    "\n",
    "pd.options.display.max_colwidth = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd55423f",
   "metadata": {},
   "source": [
    "## Util function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1112d411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_best_indices(m, topk, mask=None):\n",
    "    \"\"\"\n",
    "    Use sum of the cosine distance over all tokens.\n",
    "    m (np.array): cos matrix of shape (nb_in_tokens, nb_dict_tokens)\n",
    "    topk (int): number of indices to return (from high to lowest in order)\n",
    "    \"\"\"\n",
    "    # return the sum on all tokens of cosinus for each sentence\n",
    "    if len(m.shape) > 1:\n",
    "        cos_sim = np.mean(m, axis=0) \n",
    "    else: \n",
    "        cos_sim = m\n",
    "    index = np.argsort(cos_sim)[::-1] # from highest idx to smallest score \n",
    "    if mask is not None:\n",
    "        assert mask.shape == m.shape\n",
    "        mask = mask[index]\n",
    "    else:\n",
    "        mask = np.ones(len(cos_sim))\n",
    "    mask = np.logical_or(cos_sim[index] != 0, mask) #eliminate 0 cosine distance\n",
    "    best_index = index[mask][:topk]  \n",
    "    return best_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdde677b",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaea497",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a046d454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tahera/opt/anaconda3/envs/anly503/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['doe', 'ha', 'wa'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20000, 49932)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Adapt stop words\n",
    "token_stop = tokenizer(' '.join(STOPWORDS), lemmatize=False)\n",
    "\n",
    "# Fit TFIDF\n",
    "vectorizer = TfidfVectorizer(stop_words=token_stop, tokenizer=tokenizer) \n",
    "tfidf_mat = vectorizer.fit_transform(df['sentence'].values) # -> (num_sentences, num_vocabulary)\n",
    "tfidf_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3193b01e",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28ad1f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a crime story with a beautiful woman'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ae4e9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 20000)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>genres</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9003</th>\n",
       "      <td>Innocent Blood</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 27, 'name': 'Horror'}, {'id': 53, 'name': 'Thriller'}, {'id': 80, 'name': 'Crime'}]</td>\n",
       "      <td>A beautiful vampire turns a crime lord into a creature of the night.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10493</th>\n",
       "      <td>Requiem pour un vampire</td>\n",
       "      <td>[{'id': 27, 'name': 'Horror'}]</td>\n",
       "      <td>A vampire lures beautiful young women to his castle in Europe.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18224</th>\n",
       "      <td>Miss Bala</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}, {'id': 28, 'name': 'Action'}]</td>\n",
       "      <td>The story of a young woman clinging on to her dream to become a beauty contest queen in a Mexico dominated by organized crime.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                original_title  \\\n",
       "9003            Innocent Blood   \n",
       "10493  Requiem pour un vampire   \n",
       "18224                Miss Bala   \n",
       "\n",
       "                                                                                                                          genres  \\\n",
       "9003   [{'id': 35, 'name': 'Comedy'}, {'id': 27, 'name': 'Horror'}, {'id': 53, 'name': 'Thriller'}, {'id': 80, 'name': 'Crime'}]   \n",
       "10493                                                                                             [{'id': 27, 'name': 'Horror'}]   \n",
       "18224                                                                [{'id': 18, 'name': 'Drama'}, {'id': 28, 'name': 'Action'}]   \n",
       "\n",
       "                                                                                                                             sentence  \n",
       "9003                                                             A beautiful vampire turns a crime lord into a creature of the night.  \n",
       "10493                                                                  A vampire lures beautiful young women to his castle in Europe.  \n",
       "18224  The story of a young woman clinging on to her dream to become a beauty contest queen in a Mexico dominated by organized crime.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_recommendations_tfidf(sentence, tfidf_mat):\n",
    "    \n",
    "    \"\"\"\n",
    "    Return the database sentences in order of highest cosine similarity relatively to each \n",
    "    token of the target sentence. \n",
    "    \"\"\"\n",
    "    # Embed the query sentence\n",
    "    tokens = [str(tok) for tok in tokenizer(sentence)]\n",
    "    vec = vectorizer.transform(tokens)\n",
    "    # Create list with similarity between query and dataset\n",
    "    mat = cosine_similarity(vec, tfidf_mat)\n",
    "    # Best cosine distance for each token independantly\n",
    "    print(mat.shape)\n",
    "    best_index = extract_best_indices(mat, topk=3)\n",
    "    return best_index\n",
    "\n",
    "\n",
    "best_index = get_recommendations_tfidf(query_sentence, tfidf_mat)\n",
    "\n",
    "display(df[['original_title', 'genres', 'sentence']].iloc[best_index])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa85952a",
   "metadata": {},
   "source": [
    "# Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83cebd0",
   "metadata": {},
   "source": [
    "## Load pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca87b62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "#!python -m spacy download en_core_web_lg\n",
    "\n",
    "#Load pre-trained model\n",
    "#nlp = spacy.load(\"en_core_web_lg\") \n",
    "import en_core_web_sm\n",
    "\n",
    "nlp = en_core_web_sm.load()\n",
    "# Apply the model to the sentences\n",
    "df['spacy_sentence'] = df['sentence'].apply(lambda x: nlp(x)) \n",
    "# Retrieve the embedded vectors as a matrix \n",
    "embed_mat = df['spacy_sentence'].values\n",
    "embed_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f14262",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hl/8cs69m1n759_xb3bt3fkk4982d1l4s/T/ipykernel_47525/1677401613.py:6: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  mat = np.array([query_embed.similarity(line) for line in embed_mat])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>genres</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9003</th>\n",
       "      <td>Innocent Blood</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 27, 'name': 'Horror'}, {'id': 53, 'name': 'Thriller'}, {'id': 80, 'name': 'Crime'}]</td>\n",
       "      <td>A beautiful vampire turns a crime lord into a creature of the night.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10493</th>\n",
       "      <td>Requiem pour un vampire</td>\n",
       "      <td>[{'id': 27, 'name': 'Horror'}]</td>\n",
       "      <td>A vampire lures beautiful young women to his castle in Europe.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18224</th>\n",
       "      <td>Miss Bala</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}, {'id': 28, 'name': 'Action'}]</td>\n",
       "      <td>The story of a young woman clinging on to her dream to become a beauty contest queen in a Mexico dominated by organized crime.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                original_title  \\\n",
       "9003            Innocent Blood   \n",
       "10493  Requiem pour un vampire   \n",
       "18224                Miss Bala   \n",
       "\n",
       "                                                                                                                          genres  \\\n",
       "9003   [{'id': 35, 'name': 'Comedy'}, {'id': 27, 'name': 'Horror'}, {'id': 53, 'name': 'Thriller'}, {'id': 80, 'name': 'Crime'}]   \n",
       "10493                                                                                             [{'id': 27, 'name': 'Horror'}]   \n",
       "18224                                                                [{'id': 18, 'name': 'Drama'}, {'id': 28, 'name': 'Action'}]   \n",
       "\n",
       "                                                                                                                             sentence  \n",
       "9003                                                             A beautiful vampire turns a crime lord into a creature of the night.  \n",
       "10493                                                                  A vampire lures beautiful young women to his castle in Europe.  \n",
       "18224  The story of a young woman clinging on to her dream to become a beauty contest queen in a Mexico dominated by organized crime.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict_spacy(model, query_sentence, embed_mat, topk=5):\n",
    "    \"\"\"\n",
    "    Predict the topk sentences after applying spacy model.\n",
    "    \"\"\"\n",
    "    query_embed = model(query_sentence)\n",
    "    mat = np.array([query_embed.similarity(line) for line in embed_mat])\n",
    "    # keep if vector has a norm\n",
    "    mat_mask = np.array(\n",
    "        [True if line.vector_norm else False for line in embed_mat])\n",
    "    best_index = extract_best_indices(mat, topk=topk, mask=mat_mask)\n",
    "    return best_index\n",
    "\n",
    "# Predict\n",
    "predict_spacy(nlp, query_sentence, embed_mat)\n",
    "display(df[['original_title', 'genres', 'sentence']].iloc[best_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1443ec88",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e687e9d",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "768d6747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25184905, 33081030)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "# Create model\n",
    "word2vec_model = Word2Vec(min_count=0, workers = 8, vector_size=300) \n",
    "# Prepare vocab\n",
    "word2vec_model.build_vocab(df.tok_lem_sentence.values)\n",
    "# Train\n",
    "word2vec_model.train(df.tok_lem_sentence.values, total_examples=word2vec_model.corpus_count, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0535ee9f",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2aab7f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>genres</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9232</th>\n",
       "      <td>苏州河</td>\n",
       "      <td>[{'id': 18, 'name': 'Drama'}, {'id': 10769, 'name': 'Foreign'}, {'id': 10749, 'name': 'Romance'}]</td>\n",
       "      <td>A tragic love story set in contemporary Shanghai. The film stars Zhou Xun in a dual role as two different women and Jia Hongsheng as a man obsessed with finding a woman from his past.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>Heavy Metal</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 878, 'name': 'Science Fiction'}]</td>\n",
       "      <td>A glowing orb terrorizes a young girl with a collection of stories of dark fantasy, eroticism and horror.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10786</th>\n",
       "      <td>La sirène du Mississipi</td>\n",
       "      <td>[{'id': 80, 'name': 'Crime'}, {'id': 18, 'name': 'Drama'}, {'id': 10749, 'name': 'Romance'}]</td>\n",
       "      <td>Adapted from a story by William Irish, it's a noirish tale of a man who orders a mail-order bride but receives instead a con woman.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                original_title  \\\n",
       "9232                       苏州河   \n",
       "602                Heavy Metal   \n",
       "10786  La sirène du Mississipi   \n",
       "\n",
       "                                                                                                  genres  \\\n",
       "9232   [{'id': 18, 'name': 'Drama'}, {'id': 10769, 'name': 'Foreign'}, {'id': 10749, 'name': 'Romance'}]   \n",
       "602                            [{'id': 16, 'name': 'Animation'}, {'id': 878, 'name': 'Science Fiction'}]   \n",
       "10786       [{'id': 80, 'name': 'Crime'}, {'id': 18, 'name': 'Drama'}, {'id': 10749, 'name': 'Romance'}]   \n",
       "\n",
       "                                                                                                                                                                                      sentence  \n",
       "9232   A tragic love story set in contemporary Shanghai. The film stars Zhou Xun in a dual role as two different women and Jia Hongsheng as a man obsessed with finding a woman from his past.  \n",
       "602                                                                                  A glowing orb terrorizes a young girl with a collection of stories of dark fantasy, eroticism and horror.  \n",
       "10786                                                      Adapted from a story by William Irish, it's a noirish tale of a man who orders a mail-order bride but receives instead a con woman.  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def is_word_in_model(word, model):\n",
    "    \"\"\"\n",
    "    Check on individual words ``word`` that it exists in ``model``.\n",
    "    \"\"\"\n",
    "    assert type(model).__name__ == 'KeyedVectors'\n",
    "    is_in_vocab = word in model.key_to_index.keys()\n",
    "    return is_in_vocab\n",
    "\n",
    "def predict_w2v(query_sentence, dataset, model, topk=3):\n",
    "    query_sentence = query_sentence.split()\n",
    "    in_vocab_list, best_index = [], [0]*topk\n",
    "    for w in query_sentence:\n",
    "        # remove unseen words from query sentence\n",
    "        if is_word_in_model(w, model.wv):\n",
    "            in_vocab_list.append(w)\n",
    "    # Retrieve the similarity between two words as a distance\n",
    "    if len(in_vocab_list) > 0:\n",
    "        sim_mat = np.zeros(len(dataset))  # TO DO\n",
    "        for i, data_sentence in enumerate(dataset):\n",
    "            if data_sentence:\n",
    "                sim_sentence = model.wv.n_similarity(\n",
    "                        in_vocab_list, data_sentence)\n",
    "            else:\n",
    "                sim_sentence = 0\n",
    "            sim_mat[i] = np.array(sim_sentence)\n",
    "        # Take the five highest norm\n",
    "        best_index = np.argsort(sim_mat)[::-1][:topk]\n",
    "    return best_index\n",
    "\n",
    "# Predict\n",
    "best_index = predict_w2v(query_sentence, df['tok_lem_sentence'].values, word2vec_model)    \n",
    "display(df[['original_title', 'genres', 'sentence']].iloc[best_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48022680",
   "metadata": {},
   "source": [
    "# Transformers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d9ce9b",
   "metadata": {},
   "source": [
    "## Load pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072eba1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "corpus_embeddings = model.encode(df.sentence.values, convert_to_tensor=True)\n",
    "query_embedding = model.encode(query_sentence, convert_to_tensor=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c127179",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4832c74-e64e-40c8-a0fe-08c94b000ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# We use cosine-similarity and torch.topk to find the highest 3 scores\n",
    "cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "top_results = torch.topk(cos_scores, k=3)\n",
    "\n",
    "print(\"\\n\\n======================\\n\\n\")\n",
    "print(\"Query:\", query_sentence)\n",
    "print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "for score, idx in zip(top_results[0], top_results[1]):\n",
    "    score = score.cpu().data.numpy() \n",
    "    idx = idx.cpu().data.numpy()\n",
    "    display(df[['original_title', 'genres', 'sentence']].iloc[idx])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf3c50b-8d76-4e4c-ba0d-4b05c1294655",
   "metadata": {},
   "source": [
    "### CODE REFERENCES: \n",
    "https://github.com/topics/movie-recommendation-system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd89d4f-e6b5-408e-9ef4-5d66579565ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "f747f4033574bc018cd224c8390eda22f5cf19741325755a1e4dd992a19a8100"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
